# Selenium Web Automation - Find Below:

from selenium import webdriver
from selenium.webdriver.common.keys import Keys

# With Keys

Driver = webdriver.Firefox(executable_path='C:\\Users\\Mrinu\\Downloads\\geckodriver-v0.27.0-win64\\geckodriver')
Driver.get('https://stackoverflow.com/')
SearchBox = Driver.find_element_by_xpath('/html/body/header/div/form/div/input')
SearchBox.send_keys('Selenium Automation')
SearchBox.send_keys(Keys.ENTER)

# With Button

Driver2 = webdriver.Firefox(executable_path='C:\\Users\\Mrinu\\Downloads\\geckodriver-v0.27.0-win64\\geckodriver')
Driver2.get('https://github.com/')
SignInButton = Driver2.find_element_by_xpath('/html/body/div[1]/header/div/div[2]/div[2]/a[1]')
SignInButton.click()
LoginID = Driver2.find_element_by_xpath('//*[@id="login_field"]')
LoginID.send_keys('AnalystMrinal')
Password = Driver2.find_element_by_xpath('//*[@id="password"]')
Password.send_keys('@n@lyst1994')
LoginButton = Driver2.find_element_by_xpath('/html/body/div[3]/main/div/form/div[4]/input[9]')
LoginButton.click()







# pip install sqlalchemy - from sqlalchemy import create_engine

# Importing Data from Relational Database

Path = create_engine('Drive:\\database_path\\database.db')
Connect = path.connect()
Result = connect.execute("SELECT * FROM table")
Specific_Results = pd.DataFrame(Result.fetchall or Result.Fetchmany(size=4))




# import requests
# from bs4 import BeautifulSoup

# WEBSCRAPING 






# OS Package:

import os 

# Checking Directory:

os.listdir('Path')
              
# Importing Excel or CSV File

pd.read_csv('Drive:\\path\\FileName')



Choosing Appropriate Data Types:


# Checking the Data 

DataFrame.describe() - Like "Summary()" in R Programming - Provides everything except for median
DataFrame.info() - Like STR in R Programming - Data Type, Missing Values, Data Structure - Like class in R Programming


# Elements within the DataFrame - Int (Discrete Data), Float (Continuous), String with multiple levels - Ordinal or Nominal
  Anova - Dep Var (Continuous), Indep Var (Discrete)
  Regression - Dep Var (Continuous), Indep Var (Continuous)
  CART (Decision Trees) - Dep Var (Discrete), Indep Var (Discrete, Continuous)
  Random Forest (Classification Model) - Dep Var (Discrete), Indep Var (Discrete, Continuous)
  Logistic Regression - Dep Var (Discrete) , Indep Var (Continuous)
  Time Series Data - Time Series Structure
  Recency, Frequency & Monetary [RFM]
  Sentiment Analysis
  Market Basket Analysis
  Machine Learning

# Convert to appropriate Data Types necessary - DataFrame['Column_Name'].astype(float or int) and Multiple Levels Dummy Variables - pd.get_dummies(DataFrame,prefix=
['Column Name']) - Discrete Binary
Or getting Specific Data Types using DataFrame._get_numeric_data() or Dropping Unnecessary Rows/Columns using df_df.iloc[[0,1,2,3,4],0:4].




Dealing with Missing Data - 

Detection - DataFrame['Column_Name'].info() or DataFrame.info()

DataFrame['Column_Name'] = DataFrame['Column_Name'].fillna(DataFrame['Column_Name'].median())





Dealing with Skewed Data - Outliers

Detection - DataFrame['Column_Name'].describe() or DataFrame.describe()
            DataFrame['Column_Name'].median() or DataFrame.median()
Max_Threshold = DataFrame['Column'].quantile(0.95)
Min_Threshold = DataFrame['Column'].quantile(0.05)

DataFrame[(DataFrame['Column']<Max_Threshold) & (DataFrame['Column']>Min_Threshold)]





Data Structures - Time Series Forecasting vs Other Models - Data Frames vs Time Series Structure:

# Changing the Headings: DataFrame.rename(columns={"Col1":"New_Col1","Col2":"New_Col2"}) or 

Elements within the DataFrame Correction and Extraction:

Spelling Mistakes within Ordinal Discrete And Missing Data to NaN - 

DataFrame['Column_Name'].replace('Element','Another_Element_Of_Choice',inplace=True)





Dealing with imbalanced Data - Stratified Sampling

DataFrame.sample(Number_Of_Rows)





Python Joins And Data Retrieval: 

pd.merge(DataFrame_1,DataFrame_2,how='inner' or 'left' or 'right' or 'outer', on = 'Common_Column')

DataFrame['Column_Name'].unique()

DataFrame[(DataFrame['Column'] != <> Some_Value) & (DataFrame['Column'] != <> Some_Value)]




SQL Joins And Data Retrieval:

SELECT * FROM Mrinal_Routine;

SELECT Activity_ID FROM Mrinal_Routine
UNION
SELECT Activity_Def FROM Activity_Details;

SELECT Activities FROM Mrinal_Routine WHERE Calories_Burnt > 500;
SELECT AVG(Calories_Burnt) FROM Mrinal_Routine;
SELECT Activities,Calories_Burnt FROM Mrinal_Routine WHERE Calories_Burnt > (SELECT AVG(Calories_Burnt) FROM Mrinal_Routine);

INSERT INTO Mrinal_Routine (Day_No, Activities, Calories_Burnt, Calories_Gained, Activity_ID) VALUES (10,"Water Biking",200,0,"WB1");

SELECT * FROM Activity_Details;

INSERT INTO Activity_Details (Activity_ID, Activity_Def, Duration_Hours) VALUES ("WB1","Enhances Reaction Speed",1);

DELETE FROM Activity_Details WHERE Activity_ID = "NO2";

UPDATE Activity_Details
SET Activity_ID = "BUN2"
WHERE Activity_ID = "BUN1"; 

DELETE FROM  Mrinal_Routine WHERE Day_No = 6;

UPDATE Mrinal_Routine
SET Activities = "Bungee Jumping"
WHERE Day_No = 6;

SELECT Mrinal_Routine.Duration_Hours, Activity_Details.Duration_Hours FROM Mrinal_Routine INNER JOIN Activity_Details
ON Mrinal_Routine.Activity_ID=Activity_Details.Activity_ID;

SELECT Activity_Details.Duration_Hours, COUNT(Mrinal_Routine.Activities) 
FROM Activity_Details 
INNER JOIN Mrinal_Routine 
ON Activity_Details.Activity_ID = Mrinal_Routine.Activity_ID 
GROUP BY Activity_Details.Duration_Hours 
ORDER BY Activity_Details.Activity_ID;

SELECT M.Activities, M.Calories_Burnt, A.Activity_Def
FROM Mrinal_Routine M
LEFT JOIN Activity_Details A
ON M.Activity_ID=A.Activity_ID
UNION
SELECT M.Activities, M.Calories_Burnt, A.Activity_Def
FROM Mrinal_Routine M
LEFT JOIN Activity_Details A
ON M.Activity_ID=A.Activity_ID;

-- LEFT JOIN, RIGHT JOIN, FULL OUTER JOIN & CROSS JOIN [LEFT JOIN UNION RIGHT JOIN]

SELECT DISTINCT(Activities) FROM Mrinal_Routine;

SUM(), COUNT(), AVG(), Max(), Min()


-- CASE Function - WHERE, THEN AND ELSE STATEMENTS



# Powerful Visual Presentations with Plotly



# How to use Classes - Object Oriented Programming and Selenium for Automation in Data Science.

